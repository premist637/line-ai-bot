// âœ… å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’èª­ã¿è¾¼ã‚€
import OpenAI from "openai";
import express from "express";
import bodyParser from "body-parser";
import dotenv from "dotenv";

// âœ… ç’°å¢ƒå¤‰æ•°(.env)ã‚’ä½¿ãˆã‚‹ã‚ˆã†ã«ã™ã‚‹
dotenv.config();

const app = express();
app.use(bodyParser.json());

// âœ… OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY
});

// âœ… Webhookã‚„APIç”¨ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼ˆä¾‹ï¼‰
app.post("/webhook", async (req, res) => {
  try {
    const userMessage = req.body.message || "ã“ã‚“ã«ã¡ã¯ï¼";

    const response = await openai.chat.completions.create({
      model: "gpt-3.5-turbo",
      messages: [
        { role: "system", content: "You are a helpful assistant." },
        { role: "user", content: userMessage }
      ]
    });

    res.json({
      reply: response.choices[0].message.content
    });

  } catch (error) {
    console.error("Error:", error);
    res.status(500).json({ error: "Something went wrong" });
  }
});

// âœ… Renderã§ã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•
const PORT = process.env.PORT || 3000;
app.listen(PORT, () => {
  console.log(`ðŸš€ Server is running on port ${PORT}`);
});
